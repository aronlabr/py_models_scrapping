{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rnvdEZucJ2U5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from math import exp\n",
        "from math import log\n",
        "from math import floor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_val_split(data_X,data_Y,test_size,seed_val):\n",
        "\tdata_x = data_X.tolist()\n",
        "\tdata_y = data_Y.tolist()\n",
        "\tseed(seed_val)\n",
        "\ttrain_size = floor((1 - test_size)*len(data_x))\n",
        "\ttrain_x = []\n",
        "\ttrain_y = []\n",
        "\twhile(len(train_x)<train_size):\n",
        "\t\tindex = randrange(len(data_x))\n",
        "\t\ttrain_x.append(data_x.pop(index))\n",
        "\t\ttrain_y.append(data_y.pop(index))\n",
        "\treturn train_x,train_y,data_x,data_y"
      ],
      "metadata": {
        "id": "NmpiSfbLJ4c7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def statistics(x):\n",
        "\tcols = list(zip(*x))\n",
        "\tstats = []\n",
        "\tfor e in cols:\n",
        "\t\tstats.append([min(e),max(e)])\n",
        "\treturn stats"
      ],
      "metadata": {
        "id": "9gUgbDW8J70J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(x, stat):\n",
        "\tfor row in x:\n",
        "\t\tfor i in range(len(row)):\n",
        "\t\t\trow[i] = (row[i] - stat[i][0])/(stat[i][1] - stat[i][0])"
      ],
      "metadata": {
        "id": "s0LaGdBJSd5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_vs_all_cols(s):\n",
        "\tm = list(set(s))\n",
        "\tm.sort()\n",
        "\tfor i in range(len(s)):\n",
        "\t\tnew = [0]*len(m)\n",
        "\t\tnew[m.index(s[i])] = 1\n",
        "\t\ts[i] = new\n",
        "\treturn m"
      ],
      "metadata": {
        "id": "7CowVzRiKxRS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ThetaTX(Q,X):\n",
        "\tdet = 0.0\n",
        "\tfor i in range(len(Q)):\n",
        "\t\tdet += X[i]*Q[i]\n",
        "\treturn det"
      ],
      "metadata": {
        "id": "M_AojYbhKyHR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LinearSVM_cost0(z):\n",
        "\tif(z < -1): #Ensuring margin\n",
        "\t\treturn 0\n",
        "\treturn z + 1"
      ],
      "metadata": {
        "id": "2dFfTWoxK_uy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LinearSVM_cost1(z):\n",
        "\tif(z > 1): #Ensuring margin\n",
        "\t\treturn 0\n",
        "\treturn -z + 1"
      ],
      "metadata": {
        "id": "HSVlujh1MOiV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "\treturn 1.0/(1.0 + exp(-z))"
      ],
      "metadata": {
        "id": "AIJnGI7HLbQi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(theta,c,x,y):\n",
        "\tcost = 0.0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tz = ThetaTX(theta[c], x[i])\n",
        "\t\tcost += y[i]*LinearSVM_cost1(z) + (1 - y[i])*LinearSVM_cost0(z)\n",
        "\t\t#cost += -1*(y[i]*log(sigmoid(z)) + (1 - y[i])*log(1 - sigmoid(z)))\n",
        "\treturn cost"
      ],
      "metadata": {
        "id": "bDxMrqMHMIO6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradDescent(theta,c,x,y,learning_rate):\n",
        "\toldTheta = theta[c]\n",
        "\tfor Q in range(len(theta[c])):\n",
        "\t\tderivative_sum = 0 \n",
        "\t\tfor i in range(len(x)):\n",
        "\t\t\tderivative_sum += (sigmoid(ThetaTX(oldTheta,x[i])) - y[i])*x[i][Q]\n",
        "\t\ttheta[c][Q] -= learning_rate*derivative_sum"
      ],
      "metadata": {
        "id": "3Dmm4PKeMYix"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(data,theta):\n",
        "\tpredictions = []\n",
        "\tcount = 1\n",
        "\tfor row in data:\n",
        "\t\thypothesis = []\n",
        "\t\tmulticlass_ans = [0]*len(theta)\n",
        "\t\tfor c in range(len(theta)):\n",
        "\t\t\tz = ThetaTX(row,theta[c])\n",
        "\t\t\thypothesis.append(sigmoid(z))\n",
        "\t\tindex = hypothesis.index(max(hypothesis))\n",
        "\t\tmulticlass_ans[index] = 1\n",
        "\t\tpredictions.append(multiclass_ans)\n",
        "\t\tcount+=1\n",
        "\treturn predictions"
      ],
      "metadata": {
        "id": "8Loe3FvdMfCo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(predicted, actual):\n",
        "\tn = len(predicted)\n",
        "\tcorrect = 0\n",
        "\tfor i in range(n):\n",
        "\t\tif(predicted[i]==actual[i]):\n",
        "\t\t\tcorrect+=1\n",
        "\treturn correct/n"
      ],
      "metadata": {
        "id": "g6LfjIGdMtLp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation(x,y,test_data_size,validations,learning_rate,epoch):\n",
        "\tprint(\"No. of validation checks to be performed: \",validations)\n",
        "\tprint(\"No. of Iterations per validation: \",epoch)\n",
        "\taccuracies = []\n",
        "\tfor valid in range(validations):\n",
        "\t\tprint(\"\\nRunning Validation\",valid+1)\n",
        "\t\tx_train, y_train, x_test, y_test = cross_val_split(x,y,test_data_size,valid+1)\n",
        "\t\t#Convertir y_train en columnas de clase con valores 0/1\n",
        "\t\tclasses = []\n",
        "\t\tfor i in range(len(label_map)):\n",
        "\t\t\tclasses.append([row[i] for row in y_train])\n",
        "\t\t#Inicializando Theta (Pesos)\n",
        "\t\ttheta = [[0]*len(x_train[0]) for _ in range(len(classes))]\n",
        "\t\t#Entrenando al modelo\n",
        "\t\tfor i in range(epoch):\n",
        "\t\t\tfor class_type in range(len(classes)):\n",
        "\t\t\t\tgradDescent(theta,class_type,x_train,classes[class_type],learning_rate)\n",
        "\t\t\tif(i%(epoch/10)==0):\n",
        "\t\t\t\tprint(\"Processed\", i*100/epoch,\"%\")\n",
        "\t\tprint(\"Completed\")\n",
        "\t\t#Predecir usando datos de prueba\n",
        "\t\ty_pred = predict(x_test,theta)\n",
        "\t\t#Precisión de cálculo\n",
        "\t\taccuracies.append(accuracy(y_pred,y_test))\n",
        "\t\tprint(\"Validation\",valid+1,\"accuracy score: \",accuracies[valid])\n",
        "\treturn sum(accuracies)/len(accuracies)"
      ],
      "metadata": {
        "id": "_blblypkM3Ah"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#URL del conjunto de datos que se va a importar\n",
        "print(\"Running Forest Cover Detection using Linear SVM\\n\")\n",
        "url = \"dataset.csv\"\n",
        "dataset = pd.read_csv(url)\n",
        "data = dataset.values\n",
        "#Asignación de x e y: entidades y clases\n",
        "x = data[:,:26]\n",
        "y = data[:,27]\n",
        "#Escalado de funciones mediante el uso de estadísticas máximas y mínimas por columnas\n",
        "stats = statistics(x)\n",
        "scale(x,stats)\n",
        "#Convertir diferentes etiquetas en columnas \n",
        "#label_map se puede usar más tarde para recuperar la etiqueta de clase predicha en la forma original (formato de cadena)\n",
        "label_map = one_vs_all_cols(y)\n",
        "#Dividir el conjunto de datos en datos de entrenamiento y prueba\n",
        "test_data_size = 0.2\n",
        "learning_rate = 0.01\n",
        "epoch = 500\n",
        "validations = 5\n",
        "final_score = cross_validation(x,y,test_data_size,validations,learning_rate,epoch)\n",
        "#Impresión de estadísticas finales\n",
        "print(\"\\nReporte\")\n",
        "print(\"Modelo usado: \",\"SVM lineal con descenso de gradiente\")\n",
        "print(\"Tasa de aprendizaje: \", learning_rate)\n",
        "print(\"Nº de iteraciones: \",epoch)\n",
        "print(\"Nº de características: \", len(x[0]))\n",
        "print(\"Tamaño de los datos de entrenamiento: \", floor(len(x)*(1 - test_data_size)))\n",
        "print(\"Tamaño de datos de prueba: \", len(x) - floor(len(x)*(1 - test_data_size)))\n",
        "print(\"Nº de pruebas de validación realizadas: \", validations)\n",
        "print(\"Precisión: \",final_score*100,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbDrLHycNeNC",
        "outputId": "606844a9-c449-4ff8-c5a1-5e8ff12efdb6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Forest Cover Detection using Linear SVM\n",
            "\n",
            "No. of validation checks to be performed:  5\n",
            "No. of Iterations per validation:  500\n",
            "\n",
            "Running Validation 1\n",
            "Processed 0.0 %\n",
            "Processed 10.0 %\n",
            "Processed 20.0 %\n",
            "Processed 30.0 %\n",
            "Processed 40.0 %\n",
            "Processed 50.0 %\n",
            "Processed 60.0 %\n",
            "Processed 70.0 %\n",
            "Processed 80.0 %\n",
            "Processed 90.0 %\n",
            "Completed\n",
            "Validation 1 accuracy score:  0.9142857142857143\n",
            "\n",
            "Running Validation 2\n",
            "Processed 0.0 %\n",
            "Processed 10.0 %\n",
            "Processed 20.0 %\n",
            "Processed 30.0 %\n",
            "Processed 40.0 %\n",
            "Processed 50.0 %\n",
            "Processed 60.0 %\n",
            "Processed 70.0 %\n",
            "Processed 80.0 %\n",
            "Processed 90.0 %\n",
            "Completed\n",
            "Validation 2 accuracy score:  0.8857142857142857\n",
            "\n",
            "Running Validation 3\n",
            "Processed 0.0 %\n",
            "Processed 10.0 %\n",
            "Processed 20.0 %\n",
            "Processed 30.0 %\n",
            "Processed 40.0 %\n",
            "Processed 50.0 %\n",
            "Processed 60.0 %\n",
            "Processed 70.0 %\n",
            "Processed 80.0 %\n",
            "Processed 90.0 %\n",
            "Completed\n",
            "Validation 3 accuracy score:  0.8857142857142857\n",
            "\n",
            "Running Validation 4\n",
            "Processed 0.0 %\n",
            "Processed 10.0 %\n",
            "Processed 20.0 %\n",
            "Processed 30.0 %\n",
            "Processed 40.0 %\n",
            "Processed 50.0 %\n",
            "Processed 60.0 %\n",
            "Processed 70.0 %\n",
            "Processed 80.0 %\n",
            "Processed 90.0 %\n",
            "Completed\n",
            "Validation 4 accuracy score:  0.8476190476190476\n",
            "\n",
            "Running Validation 5\n",
            "Processed 0.0 %\n",
            "Processed 10.0 %\n",
            "Processed 20.0 %\n",
            "Processed 30.0 %\n",
            "Processed 40.0 %\n",
            "Processed 50.0 %\n",
            "Processed 60.0 %\n",
            "Processed 70.0 %\n",
            "Processed 80.0 %\n",
            "Processed 90.0 %\n",
            "Completed\n",
            "Validation 5 accuracy score:  0.8952380952380953\n",
            "\n",
            "Reporte\n",
            "Modelo usado:  SVM lineal con descenso de gradiente\n",
            "Tasa de aprendizaje:  0.01\n",
            "Nº de iteraciones:  500\n",
            "Nº de características:  26\n",
            "Tamaño de los datos de entrenamiento:  417\n",
            "Tamaño de datos de prueba:  105\n",
            "Nº de pruebas de validación realizadas:  5\n",
            "Precisión:  88.57142857142858 %\n"
          ]
        }
      ]
    }
  ]
}